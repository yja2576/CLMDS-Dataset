这两项研究都针对非自回归神经机器翻译（NAT）模型的固有局限性进行了探讨，特别是关注了多模态问题，即单一源句子有多个有效翻译会导致难以实现高质量翻译输出的挑战。第一项研究介绍了ReorderNAT框架，该框架将重排序信息纳入NAT模型的解码过程中，以指导选择属于连贯翻译的单词，从而弥合NAT与传统自回归模型之间的质量差距。这种方法不仅提高了翻译准确性，而且保持了NAT模型的推理速度优势。另一方面，第二项研究通过引入一个重述机制来解决多模态问题，该机制调整参考句子使其更接近NAT模型的输出。这种调整提供了一个更适合的训练目标，通过基于奖励函数的强化学习来优化模型，这些奖励函数衡量重述句子的适当性。这种方法显著提高了NAT的翻译质量，达到了与自回归模型相当的性能，同时速度大大提高。这两项研究都是减轻NAT模型中多模态问题的创新策略的例证，突显了非自回归方法结合高翻译质量与效率的潜力。