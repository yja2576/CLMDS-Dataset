在联邦学习（FL）领域，一种优先考虑数据隐私的协作模型训练方法，后门攻击的威胁——敌手嵌入恶意功能以触发错误分类——呈现出重大挑战。对这一领域的研究产生了创新的攻击策略和防御机制。一方面，一项研究引入了一种轻量级防御机制，该机制基于代理更新的符号信息调整聚合服务器的学习率，旨在以最小的对FL协议的修改来中和或减轻后门攻击的影响。这种方法通过实证证据支持，展示了在不损害训练模型准确性的情况下，防御此类攻击的显著改进，并提供了收敛率分析。另一方面，另一项调查揭示了Cerberus Poisoning（CerP）方法，一种复杂的分布式后门攻击策略，该策略微调恶意参与者之间的勾结，以最小化被毒化模型和干净模型之间可检测的差异，从而规避广泛的现有防御策略。通过在多个大规模数据集上进行广泛测试，并针对众多防御机制，CerP展示了FL系统对精心设计的后门攻击的持续脆弱性。这些研究共同强调了在联邦学习框架内，发展隐蔽后门攻击与制定有效防御之间持续的军备竞赛，突出了持续创新攻击检测和缓解技术以保护FL系统的完整性和安全的关键需求。