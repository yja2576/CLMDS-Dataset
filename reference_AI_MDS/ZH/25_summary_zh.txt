对联邦学习（FL）系统易受对抗性威胁的探索是一个关键的研究领域，近期的研究提出了针对这些漏洞的创新防御机制。一项研究介绍了一种防御机制，该机制基于代理更新的符号信息调整聚合服务器的学习率，旨在减轻后门攻击的风险。这种方法在显著降低后门攻击的准确性方面显示出了有效性，而不会损害整体模型的准确性。另一项研究提出了基于决策边界的联邦对抗训练（DBFAT），通过局部重新加权和全局正则化，即使在非独立同分布（non-IID）设置中，也能提高FL系统的准确性和鲁棒性。这些研究强调了在对抗特定对抗性威胁和增强对FL漏洞理解方面，强大的防御机制的重要性。然而，尽管有这些进步，最近的一篇论文揭示了一种新的威胁，Cerberus Poisoning（CerP），它表明通过仔细调整恶意参与者之间的勾结，可以实现绕过FL中广泛的最先进防御方法的隐蔽后门攻击。CerP通过共同调整后门触发器和控制每个恶意参与者上的毒化模型变化来实现这一点，对联邦学习实践的完整性和安全性构成了极其严重的威胁。这一发现突显了FL中持续对抗对抗性威胁的关键挑战，强调了为应对这些攻击的不断演变而持续创新防御策略的必要性。这些研究共同描绘了FL安全当前景观的全面图景，揭示了在确保FL系统对抗对抗性威胁的鲁棒性和弹性方面取得的进展以及面临的挑战。