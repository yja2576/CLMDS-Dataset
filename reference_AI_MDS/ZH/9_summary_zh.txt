最近在图结构数据的自监着学习（SSL）领域的进展凸显了两种不同的方法：基于增强的对比方法和预测学习模型。一方面，对无增强自监督学习框架的探索，如AFGRL，揭示了任意增强可能带来的潜在陷阱，这些增强可能会显著改变图的底层语义，从而影响对比方法的性能。AFGRL通过生成通过节点共享局部结构信息和全局语义的替代图视图来规避这一问题，展示了在各种数据集上的节点级任务中的优越性能。另一方面，Wiener图去卷积网络（WGDN）的开发展示了配备有增强自适应解码器的预测模型的力量，利用图Wiener滤波器进行增强的信息重构。这种方法不仅挑战了对比学习在图SSL中的主导地位，而且通过广泛的实验验证了其有效性。这两项研究共同强调了在图SSL中精心设计的学习框架的重要性，无论是通过避免有害的增强还是通过使用强大的解码器，都能从未标记的图数据中实现改进的表示学习。