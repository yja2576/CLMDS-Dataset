Hierarchical text classification (HTC) is a critical task in processing and organizing large volumes of text data into structured hierarchies, serving numerous real-world applications. Recent advancements in this field have explored deep learning approaches to enhance classification accuracy and efficiency. One study introduces a novel method, the Hierarchy DECoder (HiDEC), which innovatively decodes text sequences into sub-hierarchy sequences using recursive hierarchy decoding. This approach allows for the classification of multiple hierarchical levels simultaneously with fewer model parameters, achieving state-of-the-art performance on benchmark datasets. Another research effort proposes a weakly-supervised neural method that leverages minimal supervision signals, such as class-related documents or keywords, to generate pseudo documents for model pre-training. This method iteratively refines its model through self-training on real unlabeled data, featuring a hierarchical neural structure that adeptly identifies appropriate document levels within the hierarchy. Both studies address the inherent challenges of HTC, such as the need for extensive training data and the difficulty in modeling hierarchical relationships, by introducing innovative solutions that reduce model complexity and reliance on large labeled datasets. Together, these approaches signify a promising direction towards more efficient and accessible hierarchical text classification methods, catering to the diverse needs of applications requiring structured document organization and classification.