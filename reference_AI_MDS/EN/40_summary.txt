Both studies delve into the realm of multitask learning, specifically targeting the enhancement of joint entity and relation extraction tasks, albeit through distinct methodologies and frameworks. The first research introduces a unified multi-task learning framework that divides the task into three interconnected sub-tasks: type-attentional subject extraction, subject-aware relation prediction, and a question generation based QA method for object extraction. This approach notably addresses challenges such as template-dependency, non-entity detection, and non-predefined relation prediction by integrating these sub-tasks into a cohesive model through parameter sharing, demonstrating superior performance on benchmark datasets. On the other hand, the second study proposes a Progressive Multitask learning model with Explicit Interactions (PMEI), which leverages the correlations between outputs of related tasks, such as entity recognition and relation extraction, to extract relevant features from the input. By controlling the injection of early predictions, this model aims to refine task-specific representations for classification, achieving state-of-the-art results on joint entity and relation extraction tasks. Both studies underscore the potential of multitask learning in improving the accuracy and efficiency of extracting entities and their relations, yet they adopt different strategies to exploit the inherent correlations between tasks and to overcome the limitations of existing models.