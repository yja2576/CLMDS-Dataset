Recent advancements in artificial intelligence have focused on enhancing the human-machine interaction experience, particularly through the development of open-domain neural conversational models. One study introduces an end-to-end affect-rich conversational model that not only focuses on syntax and semantics but also incorporates affect, using Valence, Arousal, and Dominance (VAD) affective notations for word embedding. This model is further refined with an affective attention mechanism and an affect-incorporated objective function, leading to the generation of more natural and affect-rich responses, as confirmed by evaluations. Another research effort tackles the challenge of guiding conversational agents towards specific conversational goals or keywords, aiming to improve applications in areas such as recommendation systems and psychotherapy. This approach leverages external commonsense knowledge graphs (CKG) to enhance keyword transition and response retrieval, showing that incorporating commonsense knowledge results in smoother keyword transitions and faster achievement of target keywords. Both studies underscore the importance of context and additional linguistic dimensions—be it affect or commonsense knowledge—in improving the quality and applicability of conversational agents, highlighting a trend towards more nuanced and human-like interactions in the field of conversational AI.