Both studies address the inherent limitations of non-autoregressive neural machine translation (NAT) models, particularly focusing on the multimodality problem where multiple valid translations for a single source sentence lead to challenges in achieving high-quality translation outputs. The first study introduces the ReorderNAT framework, which incorporates reordering information into the decoding process of NAT models to guide the selection of words that belong to a coherent translation, thereby bridging the quality gap between NAT and traditional autoregressive models. This approach not only enhances translation accuracy but also maintains the inference speed advantage of NAT models. On the other hand, the second study tackles the multimodality issue by introducing a rephraser mechanism that adjusts the reference sentence closer to the NAT model's output. This adjustment provides a more suitable training target, optimizing the model through reinforcement learning based on reward functions that measure the appropriateness of the rephrased sentences. This method significantly improves NAT's translation quality, achieving performance on par with autoregressive models while being substantially faster. Both studies exemplify innovative strategies to mitigate the multimodality problem in NAT models, highlighting the potential for non-autoregressive approaches to combine high translation quality with efficiency.