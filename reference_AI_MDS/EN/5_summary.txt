Both studies address the challenge of leveraging sparse or unlabeled data in their respective fields through innovative self-supervised learning frameworks, highlighting the adaptability and potential of self-supervised methods across different domains. In the medical imaging domain, a novel approach is introduced that employs two levels of self-supervised representation learning objectives, focusing on the anatomical and patient levels, and utilizes graph neural networks to understand the relationship between different anatomical regions. This method demonstrates its effectiveness in handling large-scale Computer Tomography (CT) datasets of lung images, particularly in identifying clinically relevant regions and quantifying the clinical progression of COVID-19, showcasing its ability to generalize across patients from different hospitals. On the other hand, in the field of intelligent education, a Self-supervised Cognitive Diagnosis (SCD) framework is proposed to tackle the Long Tail Effect in cognitive diagnosis by improving the diagnosis accuracy for students with sparse interaction records. This is achieved through a graph confusion method that generates sparse views of the graph to enhance the focus on long-tailed students and an importance-based view generation rule to amplify their influence. Both studies not only demonstrate the versatility of self-supervised learning in extracting meaningful insights from sparse or unlabeled datasets but also underscore the importance of context-specific adaptations—whether it be the anatomical context in medical imaging or the individual proficiency levels in cognitive diagnosis—to effectively address domain-specific challenges.